{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1105e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import open3d as o3d\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27e37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result_original_color(source, target, transformation, source_file):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.transform(transformation)\n",
    "    \n",
    "    # 入力ファイル名の末尾に \"_colored_icp\" を追加して新しいファイル名を生成\n",
    "    source_path = Path(source_file)  # 引数として受け取ったファイル名を使用\n",
    "    new_filename = source_path.stem + \"_colored_icp.ply\"  # \"_colored_icp\" を追加\n",
    "    new_path = source_path.with_name(new_filename)\n",
    "\n",
    "    # 変換された点群を新しいファイル名で保存\n",
    "    o3d.io.write_point_cloud(str(new_path), source_temp)\n",
    "    print(\"save \",new_filename)\n",
    "    # 点群を視覚化\n",
    "    o3d.visualization.draw_geometries([source_temp, target],\n",
    "                                      zoom=0.5,\n",
    "                                      front=[-0.2458, -0.8088, 0.5342],\n",
    "                                      lookat=[1.7745, 2.2305, 0.9787],\n",
    "                                      up=[0.3109, -0.5878, -0.7468])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445db34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Load two point clouds and show initial pose\n",
      "save  0013_transformed_colored_icp.ply\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"1. Load two point clouds and show initial pose\")\n",
    "source_path=\"output/0013/0013_transformed.ply\"\n",
    "target_path=\"output/0014/0014_transformed.ply\"\n",
    "# source_path=\"0005_norm.ply\"\n",
    "# target_path=\"0006_norm.ply\"\n",
    "source = o3d.io.read_point_cloud(source_path)\n",
    "target = o3d.io.read_point_cloud(target_path)\n",
    "\n",
    "# draw initial alignment\n",
    "current_transformation = np.identity(4)\n",
    "draw_registration_result_original_color(source, target, current_transformation, source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e070d28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Point-to-point ICP registration is applied on original point\n",
      "   clouds to refine the alignment. Distance threshold 0.2.\n",
      "RegistrationResult with fitness=9.986592e-01, inlier_rmse=6.544929e-02, and correspondence_set size of 309095\n",
      "Access transformation to get result.\n",
      "save  0005_norm_colored_icp.ply\n"
     ]
    }
   ],
   "source": [
    "# point to point ICP\n",
    "current_transformation = np.identity(4)\n",
    "print(\"2. Point-to-point ICP registration is applied on original point\")\n",
    "print(\"   clouds to refine the alignment. Distance threshold 0.2.\")\n",
    "result_icp = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, 0.3, current_transformation,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "print(result_icp)\n",
    "draw_registration_result_original_color(source, target, result_icp.transformation, source_path)\n",
    "icp_trans=result_icp.transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ICP with decreasing distance threshold...\n",
      "Trying with distance threshold: 1\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=5.362144e-02, and correspondence_set size of 235205\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.5\n",
      "RegistrationResult with fitness=9.999915e-01, inlier_rmse=5.358711e-02, and correspondence_set size of 235203\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.25\n",
      "RegistrationResult with fitness=9.999915e-01, inlier_rmse=5.358671e-02, and correspondence_set size of 235203\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.125\n",
      "RegistrationResult with fitness=9.207160e-01, inlier_rmse=3.427111e-02, and correspondence_set size of 216557\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.0625\n",
      "RegistrationResult with fitness=8.176399e-01, inlier_rmse=1.827909e-02, and correspondence_set size of 192313\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.03125\n",
      "RegistrationResult with fitness=7.233987e-01, inlier_rmse=9.548584e-03, and correspondence_set size of 170147\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.015625\n",
      "RegistrationResult with fitness=6.309432e-01, inlier_rmse=5.061557e-03, and correspondence_set size of 148401\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.0078125\n",
      "RegistrationResult with fitness=5.472885e-01, inlier_rmse=3.060437e-03, and correspondence_set size of 128725\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.00390625\n",
      "RegistrationResult with fitness=4.325886e-01, inlier_rmse=1.832628e-03, and correspondence_set size of 101747\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.001953125\n",
      "RegistrationResult with fitness=2.987522e-01, inlier_rmse=1.089636e-03, and correspondence_set size of 70268\n",
      "Access transformation to get result.\n",
      "Trying with distance threshold: 0.0009765625\n",
      "RegistrationResult with fitness=1.589294e-01, inlier_rmse=6.187730e-04, and correspondence_set size of 37381\n",
      "Access transformation to get result.\n",
      "save  0013_transformed_colored_icp.ply\n",
      "Finished ICP with decreasing distance threshold.\n"
     ]
    }
   ],
   "source": [
    "# Initial transformation\n",
    "current_transformation = np.identity(4)\n",
    "\n",
    "# Initial distance threshold\n",
    "initial_threshold = 1\n",
    "min_threshold = 0.0005  # Minimum threshold value\n",
    "threshold_decrement = 0.05  # Amount to decrease the threshold\n",
    "threshold = initial_threshold\n",
    "\n",
    "print(\"Starting ICP with decreasing distance threshold...\")\n",
    "while threshold >= min_threshold:\n",
    "    print(f\"Trying with distance threshold: {threshold}\")\n",
    "    \n",
    "    # Point-to-point ICP registration\n",
    "    result_icp = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, current_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    \n",
    "    print(result_icp)\n",
    "\n",
    "    \n",
    "    # Update the current transformation for the next iteration\n",
    "    current_transformation = result_icp.transformation\n",
    "    \n",
    "    # Decrease the threshold\n",
    "    threshold /= 2\n",
    "draw_registration_result_original_color(source, target,\n",
    "                                        result_icp.transformation, source_path)\n",
    "print(\"Finished ICP with decreasing distance threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c478b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans=result_icp.transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f08b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Colored point cloud registration\n",
      "[50, 0.04, 0]\n",
      "3-1. Downsample with a voxel size 0.04\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "RegistrationResult with fitness=6.520412e-01, inlier_rmse=1.940616e-02, and correspondence_set size of 1709\n",
      "Access transformation to get result.\n",
      "[30, 0.02, 1]\n",
      "3-1. Downsample with a voxel size 0.02\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "RegistrationResult with fitness=5.057555e-01, inlier_rmse=1.007513e-02, and correspondence_set size of 3471\n",
      "Access transformation to get result.\n",
      "[14, 0.01, 2]\n",
      "3-1. Downsample with a voxel size 0.01\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "RegistrationResult with fitness=3.751262e-01, inlier_rmse=5.228980e-03, and correspondence_set size of 6690\n",
      "Access transformation to get result.\n",
      "save  0013_transformed_colored_icp.ply\n"
     ]
    }
   ],
   "source": [
    "# colored pointcloud registration\n",
    "# This is implementation of following paper\n",
    "# J. Park, Q.-Y. Zhou, V. Koltun,\n",
    "# Colored Point Cloud Registration Revisited, ICCV 2017\n",
    "voxel_radius = [0.04, 0.02, 0.01]\n",
    "max_iter = [50, 30, 14]\n",
    "current_transformation = np.identity(4)\n",
    "print(\"3. Colored point cloud registration\")\n",
    "for scale in range(3):\n",
    "    iter = max_iter[scale]\n",
    "    radius = voxel_radius[scale]\n",
    "    print([iter, radius, scale])\n",
    "\n",
    "    print(\"3-1. Downsample with a voxel size %.2f\" % radius)\n",
    "    source_down = source.voxel_down_sample(radius)\n",
    "    target_down = target.voxel_down_sample(radius)\n",
    "\n",
    "    print(\"3-2. Estimate normal.\")\n",
    "    source_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "    target_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n",
    "\n",
    "    print(\"3-3. Applying colored point cloud registration\")\n",
    "    result_icp = o3d.pipelines.registration.registration_colored_icp(\n",
    "        source_down, target_down, radius, current_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                          relative_rmse=1e-6,\n",
    "                                                          max_iteration=iter))\n",
    "    current_transformation = result_icp.transformation\n",
    "    print(result_icp)\n",
    "draw_registration_result_original_color(source, target,\n",
    "                                        result_icp.transformation, source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb946b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Colored point cloud registration\n",
      "[500, 0.04, 0]\n",
      "3-1. Estimate normal if not already done.\n",
      "3-2. Applying colored point cloud registration\n",
      "RegistrationResult with fitness=4.906186e-01, inlier_rmse=1.861955e-02, and correspondence_set size of 116727\n",
      "Access transformation to get result.\n",
      "[30, 0.02, 1]\n",
      "3-1. Estimate normal if not already done.\n",
      "3-2. Applying colored point cloud registration\n",
      "RegistrationResult with fitness=3.140620e-01, inlier_rmse=1.077780e-02, and correspondence_set size of 74721\n",
      "Access transformation to get result.\n",
      "[14, 0.01, 2]\n",
      "3-1. Estimate normal if not already done.\n",
      "3-2. Applying colored point cloud registration\n",
      "RegistrationResult with fitness=1.054103e-01, inlier_rmse=6.233110e-03, and correspondence_set size of 25079\n",
      "Access transformation to get result.\n",
      "save  0012_norm_colored_icp.ply\n"
     ]
    }
   ],
   "source": [
    "# colored pointcloud registration\n",
    "# This is implementation of following paper\n",
    "# J. Park, Q.-Y. Zhou, V. Koltun,\n",
    "# Colored Point Cloud Registration Revisited, ICCV 2017\n",
    "\n",
    "transformed_source = copy.deepcopy(source)\n",
    "transformed_source.transform(trans)\n",
    "\n",
    "max_iter = [500, 30, 14]\n",
    "voxel_radius = [0.04, 0.02, 0.01]\n",
    "current_transformation = result_icp.transformation\n",
    "print(\"3. Colored point cloud registration\")\n",
    "\n",
    "for scale in range(3):\n",
    "    iter = max_iter[scale]\n",
    "    radius = voxel_radius[scale]\n",
    "    print([iter, radius, scale])\n",
    "\n",
    "    # 使用する法線は元のPLYファイルから取得\n",
    "    print(\"3-1. Estimate normal if not already done.\")\n",
    "\n",
    "\n",
    "    print(\"3-2. Applying colored point cloud registration\")\n",
    "    result_icp = o3d.pipelines.registration.registration_colored_icp(\n",
    "        transformed_source, target, radius, current_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n",
    "                                                          relative_rmse=1e-6,\n",
    "                                                          max_iteration=iter))\n",
    "    current_transformation = result_icp.transformation\n",
    "    print(result_icp)\n",
    "\n",
    "draw_registration_result_original_color(transformed_source, target,\n",
    "                                        result_icp.transformation, source_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e9e38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICP result: RegistrationResult with fitness=7.778394e-01, inlier_rmse=4.234602e-02, and correspondence_set size of 185062\n",
      "Access transformation to get result.\n",
      "Transformation matrix: [[ 9.99980802e-01 -7.45034203e-04 -6.15150423e-03  7.81254183e-03]\n",
      " [ 9.77048848e-04  9.99284836e-01  3.78003007e-02 -2.66583505e-02]\n",
      " [ 6.11894238e-03 -3.78055853e-02  9.99266379e-01  9.93331776e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 3. source に変換 trans を適用し、新しい点群として保存\n",
    "transformed_source = copy.deepcopy(source)\n",
    "transformed_source.transform(trans)\n",
    "\n",
    "# 初期変換を適用した点群を可視化\n",
    "o3d.visualization.draw_geometries([transformed_source, target], window_name=\"Initial Alignment\")\n",
    "\n",
    "# 4. 通常のICPを適用\n",
    "threshold = 0.1  # ICPのしきい値を設定\n",
    "initial_transformation = np.identity(4)\n",
    "result_icp = o3d.pipelines.registration.registration_icp(\n",
    "    transformed_source, target, threshold, initial_transformation,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    ")\n",
    "\n",
    "# 5. 結果を表示\n",
    "print(\"ICP result:\", result_icp)\n",
    "print(\"Transformation matrix:\", result_icp.transformation)\n",
    "\n",
    "# 6. ICP後の位置合わせ結果を可視化\n",
    "aligned_source = copy.deepcopy(transformed_source)\n",
    "aligned_source.transform(result_icp.transformation)\n",
    "\n",
    "o3d.visualization.draw_geometries([aligned_source, target], window_name=\"ICP Alignment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55495198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65184eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07a2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "\n",
    "    source = o3d.io.read_point_cloud(source_path)\n",
    "    target = o3d.io.read_point_cloud(target_path)\n",
    "    # trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "    #                          [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    # source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c21fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.05  # means 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(\n",
    "    voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6d9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6eba49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.050,\n",
      "   we use a liberal distance threshold 0.075.\n",
      "RegistrationResult with fitness=8.098481e-01, inlier_rmse=3.646758e-02, and correspondence_set size of 1546\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "print(result_ransac)\n",
    "draw_registration_result(source_down, target_down, result_ransac.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4c849a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_ransac.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Point-to-plane ICP registration is applied on original point\n",
      "   clouds to refine the alignment. This time we use a strict\n",
      "   distance threshold 0.020.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[1;31m[Open3D Error] (open3d::pipelines::registration::RegistrationResult open3d::pipelines::registration::RegistrationICP(const open3d::geometry::PointCloud&, const open3d::geometry::PointCloud&, double, const Matrix4d&, const open3d::pipelines::registration::TransformationEstimation&, const open3d::pipelines::registration::ICPConvergenceCriteria&)) /root/Open3D/cpp/open3d/pipelines/registration/Registration.cpp:128: TransformationEstimationPointToPlane and TransformationEstimationColoredICP require pre-computed normal vectors for target PointCloud.\n\u001b[0;m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result_icp \u001b[38;5;241m=\u001b[39m \u001b[43mrefine_registration\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_fpfh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_fpfh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mvoxel_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_icp)\n\u001b[1;32m      4\u001b[0m draw_registration_result(source, target, result_icp\u001b[38;5;241m.\u001b[39mtransformation)\n",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m, in \u001b[0;36mrefine_registration\u001b[0;34m(source, target, source_fpfh, target_fpfh, voxel_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   clouds to refine the alignment. This time we use a strict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   distance threshold \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m distance_threshold)\n\u001b[0;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration_icp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_ransac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformationEstimationPointToPlane\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[1;31m[Open3D Error] (open3d::pipelines::registration::RegistrationResult open3d::pipelines::registration::RegistrationICP(const open3d::geometry::PointCloud&, const open3d::geometry::PointCloud&, double, const Matrix4d&, const open3d::pipelines::registration::TransformationEstimation&, const open3d::pipelines::registration::ICPConvergenceCriteria&)) /root/Open3D/cpp/open3d/pipelines/registration/Registration.cpp:128: TransformationEstimationPointToPlane and TransformationEstimationColoredICP require pre-computed normal vectors for target PointCloud.\n\u001b[0;m"
     ]
    }
   ],
   "source": [
    "result_icp = refine_registration(source, target, source_fpfh, target_fpfh,\n",
    "                                 voxel_size)\n",
    "print(result_icp)\n",
    "draw_registration_result(source, target, result_icp.transformation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275d295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70334a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
